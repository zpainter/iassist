+++
nid = "3379"
uid = "170"
author = "michellehudson"
title = "Some reflections on research data confidentiality, privacy, and curation by Limor Peer"
tags = [ "Community of Data Professionals", "Archiving, Preservation, Curation", "Data Access & Open Data", "IASSIST 2012", "Research Data Management", "Social Science Datasets", "Tools, Apps, Technology",]
oldpath = "/blog/some-reflections-research-data-confidentiality-privacy-and-curation-limor-peer"
date = "2013-03-07 11:43:38 -0700"
draft = "false"
+++
**Some reflections on research data confidentiality, privacy, and
curation**

Limor Peer

Maintaining research subjects' confidentiality is an essential feature
of the scientific research enterprise. It also presents special
challenges to the data curation process. Does the effort to open access
to research data complicate these challenges?

A few reasons why I think it does: More data are discoverable and could
be used to re-identify previously de-identified datasets; systems are
increasingly interoperable, potentially bridging what may have been
insular academic data with other data and information sources; growing
pressure to open data may weaken some of the safeguards previously put
in place; and some data are inherently
[identifiable](http://www.personalgenomes.org/considerations.html).Â 

But these challenges should not diminish the scientific community's firm
commitment to both principles. It is possible, and desirable, for
openness and privacy co-exist. It will not be simple to do, and here's
what we need to keep in mind:

First, let's be clear about semantics. Open data and public data are not
the same thing. As [Melanie Chernoff
observed](http://opensource.com/government/10/12/what-%E2%80%9Copen-data%E2%80%9D-means-%E2%80%93-and-what-it-doesn%E2%80%99t#comment-3001),
"All open data is publicly available. But not all publicly available
data is open." This distinction is important because what our community
means by open (standards, format) may not be what policy-makers and the
public at large mean (public access). Chernoff rightly points out that
"whether data should be made publicly available is where privacy
concerns come into play. Once it has been determined that government
data should be made public, then it should be done so in an open
format." So, yes, we want as much data as possible to be public, but we
most definitely want data to be open.

Another term that could be clarified is usefulness. In the academic
context, we often think of data re-use by other scholars, in the service
of advancing science. But what if the individuals from whom the data
were collected are the ones who want to make use of it? It's entirely
conceivable that the people formerly known as "research subjects" begin
demanding access to, and control over, their own personal data as they
become more accustomed to that in other contexts. This will require some
fresh ideas about regulation and some rethinking of the concept of
informed consent (see, for example, the work of [John
Wilbanks](http://weconsent.us/informed-consent/),
[NIH](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3216676/), and the
[National Cancer
Institute](http://epi.grants.cancer.gov/workshops/identifiability/think-tank-summary.pdf)
on this front). The academic community is going to have to confront this
issue.

Precisely because terms are confusing and often vaguely defined, we
should use them carefully. It's tempting to pit one term against the
other, e.g., usefulness vs. privacy, but it may not be productive. The
tension between privacy and openness or transparency does not mean that
we have to choose one over the other. As [Felix Wu
says](http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2031808),
"there is nothing inherently contradictory about hiding one piece of
information while revealing another, so long as the information we want
to hide is different from the information we want to disclose." The
complex reality is that we have to weigh them carefully and make
context-based decisions.

I think the IASSIST community is in a position to lead on this front, as
it is intimately familiar with issues of disclosure risk. Just last
spring, the 2012 IASSIST conference included a [panel on
confidentiality, privacy and
security](http://www.iassist2012.org/indexfolder/program/index.php?show=session:N).
IASSIST has a [special interest group on Human Subjects Review
Committees and Privacy and Confidentiality in
Research](http://iassistdata.org/about/committees.html#interest).
Various IASSIST members have been involved with heroic efforts to create
solutions (e.g., via the DDI Alliance, UKDA and ICPSR protocols) and
educate about the issue (e.g., [ICPSR
webinar](http://www.disc.wisc.edu/discnews/index.php/archives/140) ,
[ICPSR summer
course](http://www.icpsr.umich.edu/icpsrweb/sumprog/courses/0115), and
[MANTRA module](http://datalib.edina.ac.uk/mantra/dataprotection.html)).
A recent panel at the [International Data Curation
Conference](http://www.dcc.ac.uk/events/idcc13/programme-presentations)
in Amsterdam showcased IASSIST members' strategies for dealing with this
issue ([see my reflections about the
panel](http://www.dcc.ac.uk/blog/idcc13-panel-confidentiality-and-open-access-research-data)).

It might be the case that STEM is leading the push for open data, but
these disciplines are increasingly
[confronted](http://www.nature.com/news/genetic-privacy-needs-a-more-nuanced-approach-1.12363)
with [problems of
re-identification](http://www.nytimes.com/2013/01/18/health/search-of-dna-sequences-reveals-full-identities.html?_r=2&),
while the private sector is increasingly being scrutinized for its
practices (see this on "[data
hops](http://www.mediapost.com/publications/article/194073/suicide-by-cookies.html#axzz2Lp3rwl8B)").
The social (and, of course, medical) sciences have a well-developed
regulatory framework around the issue of research ethics that many of us
have been steeped in. Government agencies have their own approaches and
standards (see [recent report](http://www.gao.gov/products/GAO-13-106)
by the U.S. Government Accountability office). IASSIST can provide a
bridge; we have the opportunity to help define the conversation and
offer some solutions.
